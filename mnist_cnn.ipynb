{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Digit Classification using MNIST dataset\n",
    "\n",
    "This tutoral will show you:\n",
    "- How to load a dataset in TensorFlow and batch iterate through the data\n",
    "- Define the computation graph of a convolutional neural net and train it\n",
    "- Save checkpoints during training\n",
    "- Visualize filters and feature maps in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset\n",
    "\n",
    "MNIST is a simple computer vision dataset. \n",
    "- It consists of images of handwritten digits from 0-9, and their image labels;\n",
    "- Each image is 28px * 28px;\n",
    "- The input image is flattened into a vector of 28x28 = 784 numbers, so MNIST images is a tensor (an n-dimensional array) with a shape of [55000, 784];\n",
    "- MNIST labels is a [55000, 1] array of numbers.\n",
    "\n",
    "<img src=\"images/mnist-train-xs.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "Here, we provide you a ``DataLoader`` class to load dataset into memory. \n",
    "Two methods are provided to access training and testing data.\n",
    "- next_batch: return next batch of training data\n",
    "- load_test: return all testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107aa0810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = 'MNIST_data/'\n",
    "h = 28  # MNIST image size: 28*28px\n",
    "w = 28\n",
    "c = 1   # MNIST data has only one channel, they are grey scale images\n",
    "\n",
    "from data_loader import DataLoader\n",
    "\n",
    "# Construct dataloader to load MNIST dataset\n",
    "loader = DataLoader(data_dir, w, h, c)\n",
    "\n",
    "# Plot one image and label\n",
    "plt.imshow(loader.dataset.train.images[0].reshape(h, w)).set_cmap('Greys')\n",
    "print(\"Label: %d\" % loader.dataset.train.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Compuation Graph\n",
    "\n",
    "In TensorFlow, a computation graph defines the architecture of neural network. All needed functions to define layers and losses are in ``tf.nn`` module: https://www.tensorflow.org/api_docs/python/tf/nn\n",
    "\n",
    "The following cell gives you a graph of basic CNN. The network repeats \"Convoluation + Non-linearity + Pooling\" twice. We provide the weights and biases for each layer but didn't fill in the details of those layers. Here are the APIs you need:\n",
    "- [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d): use stride 1, filter size is defined in ``weights``\n",
    "- [tf.nn.relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu)\n",
    "- [tf.nn.max_pool](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool): use 2x2 filter and stride 2\n",
    "\n",
    "To better understand what the model learns, we created utility functions in ``visualizer.py`` to visualize convolution kernels and layer outputs. When defining computation graph, we need to add the interesting variables to image summary so that we can see them in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    \"\"\" Random initialize weight variable \"\"\"\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def init_bias(shape):\n",
    "    \"\"\" Initialize bias variable to zero \"\"\"\n",
    "    return tf.Variable(tf.zeros(shape))\n",
    "\n",
    "def cnn(x, keep_dropout):\n",
    "    \"\"\" Define the CNN computation graph \"\"\"\n",
    "\n",
    "    weights = {\n",
    "        'wc1': init_weights([5, 5, 1, 32]),   # 5x5x1 conv, 32 outputs\n",
    "        'wc2': init_weights([5, 5, 32, 64]),  # 5x5x32 conv, 64 outputs\n",
    "        'wf3': init_weights([7*7*64, 1024]),  # Fully Connected 7*7*64 inputs, 1024 outputs\n",
    "        'wo': init_weights([1024, 10]),       # Fully Connected 1024 inputs, 10 outputs \n",
    "    }\n",
    "    biases = {\n",
    "        'bc1': init_bias(32),\n",
    "        'bc2': init_bias(64),\n",
    "        'bf3': init_bias(1024),\n",
    "        'bo': init_bias(10),\n",
    "    }\n",
    "    \n",
    "    from visualizer import visualize_filter, visualize_feature\n",
    "\n",
    "    # Convolution + ReLU + Pooling\n",
    "    conv1 = tf.nn.conv2d(x, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, biases['bc1']))\n",
    "    pool1 = tf.nn.max_pool(relu1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    tf.summary.image('kernel1', visualize_filter(weights['wc1']), max_outputs=1)\n",
    "    tf.summary.image('relu1',visualize_feature(relu1), max_outputs=1)\n",
    "    tf.summary.image('pool1',visualize_feature(pool1), max_outputs=1)\n",
    "\n",
    "    # Convolution + ReLU + Pooling\n",
    "    conv2 = tf.nn.conv2d(pool1, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, biases['bc2']))\n",
    "    pool2 = tf.nn.max_pool(relu2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    tf.summary.image('kernel2', visualize_filter(weights['wc2']), max_outputs=1)\n",
    "    tf.summary.image('relu2',visualize_feature(relu2), max_outputs=1)\n",
    "    tf.summary.image('pool2',visualize_feature(pool2), max_outputs=1)\n",
    "\n",
    "    # Fully Connected + ReLU + Dropout\n",
    "    fc3 = tf.reshape(pool2, [-1, weights['wf3'].get_shape().as_list()[0]])\n",
    "    fc3 = tf.add(tf.matmul(fc3, weights['wf3']), biases['bf3'])\n",
    "    fc3 = tf.nn.relu(fc3)\n",
    "    fc3 = tf.nn.dropout(fc3, keep_dropout)\n",
    "\n",
    "    # Output Fully Connected\n",
    "    out = tf.add(tf.matmul(fc3, weights['wo']), biases['bo'])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for training\n",
    "learning_rate = 0.001\n",
    "training_iters = 500\n",
    "batch_size = 100\n",
    "step_display = 10\n",
    "step_save = 500\n",
    "path_save = 'models/mnist_cnn'\n",
    "\n",
    "# Network Parameters\n",
    "dropout = 0.5  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can train the model, we also need to decide which loss and optimizer we want to use for back propagation. Here are some optimizer you can try:\n",
    "- [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)\n",
    "- [tf.train.AdadeltaOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdadeltaOptimizer)\n",
    "- [tf.train.AdagradOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer)\n",
    "- [tf.train.AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define input of computation graph\n",
    "x = tf.placeholder(tf.float32, [None, h, w, c])\n",
    "y = tf.placeholder(tf.int64, None)\n",
    "keep_dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "# Construct model\n",
    "logits = cnn(x, keep_dropout)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "train_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Set up model evaluation metrics\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Define saver to write out model checkpoint\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Configure summary writer to write out logs\n",
    "LOG_DIR = \"logs\"\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Now, we're ready to run training on the data batches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10, Minibatch Loss = 1.862742, Training Accuracy = 0.5200\n",
      "Iter 20, Minibatch Loss = 0.778925, Training Accuracy = 0.6600\n",
      "Iter 30, Minibatch Loss = 0.782985, Training Accuracy = 0.6900\n",
      "Iter 40, Minibatch Loss = 0.504283, Training Accuracy = 0.8500\n",
      "Iter 50, Minibatch Loss = 0.294770, Training Accuracy = 0.8700\n",
      "Iter 60, Minibatch Loss = 0.381130, Training Accuracy = 0.9000\n",
      "Iter 70, Minibatch Loss = 0.259445, Training Accuracy = 0.9500\n",
      "Iter 80, Minibatch Loss = 0.366366, Training Accuracy = 0.8800\n",
      "Iter 90, Minibatch Loss = 0.402122, Training Accuracy = 0.9000\n",
      "Iter 100, Minibatch Loss = 0.203817, Training Accuracy = 0.9100\n",
      "Iter 110, Minibatch Loss = 0.290456, Training Accuracy = 0.9400\n",
      "Iter 120, Minibatch Loss = 0.153579, Training Accuracy = 0.9400\n",
      "Iter 130, Minibatch Loss = 0.186846, Training Accuracy = 0.9200\n",
      "Iter 140, Minibatch Loss = 0.057914, Training Accuracy = 0.9800\n",
      "Iter 150, Minibatch Loss = 0.084986, Training Accuracy = 0.9500\n",
      "Iter 160, Minibatch Loss = 0.180626, Training Accuracy = 0.9300\n",
      "Iter 170, Minibatch Loss = 0.142753, Training Accuracy = 0.9400\n",
      "Iter 180, Minibatch Loss = 0.032903, Training Accuracy = 1.0000\n",
      "Iter 190, Minibatch Loss = 0.138572, Training Accuracy = 0.9800\n",
      "Iter 200, Minibatch Loss = 0.103487, Training Accuracy = 0.9600\n",
      "Iter 210, Minibatch Loss = 0.084723, Training Accuracy = 0.9900\n",
      "Iter 220, Minibatch Loss = 0.029783, Training Accuracy = 1.0000\n",
      "Iter 230, Minibatch Loss = 0.084513, Training Accuracy = 0.9700\n",
      "Iter 240, Minibatch Loss = 0.069870, Training Accuracy = 0.9800\n",
      "Iter 250, Minibatch Loss = 0.109576, Training Accuracy = 0.9600\n",
      "Iter 260, Minibatch Loss = 0.091283, Training Accuracy = 0.9600\n",
      "Iter 270, Minibatch Loss = 0.095408, Training Accuracy = 0.9800\n",
      "Iter 280, Minibatch Loss = 0.038347, Training Accuracy = 0.9800\n",
      "Iter 290, Minibatch Loss = 0.031746, Training Accuracy = 1.0000\n",
      "Iter 300, Minibatch Loss = 0.091043, Training Accuracy = 0.9800\n",
      "Iter 310, Minibatch Loss = 0.094307, Training Accuracy = 0.9600\n",
      "Iter 320, Minibatch Loss = 0.033550, Training Accuracy = 0.9900\n",
      "Iter 330, Minibatch Loss = 0.057622, Training Accuracy = 0.9800\n",
      "Iter 340, Minibatch Loss = 0.100889, Training Accuracy = 0.9700\n",
      "Iter 350, Minibatch Loss = 0.055099, Training Accuracy = 0.9900\n",
      "Iter 360, Minibatch Loss = 0.063318, Training Accuracy = 0.9800\n",
      "Iter 370, Minibatch Loss = 0.093611, Training Accuracy = 0.9600\n",
      "Iter 380, Minibatch Loss = 0.123841, Training Accuracy = 0.9700\n",
      "Iter 390, Minibatch Loss = 0.091691, Training Accuracy = 0.9800\n",
      "Iter 400, Minibatch Loss = 0.076224, Training Accuracy = 0.9600\n",
      "Iter 410, Minibatch Loss = 0.059393, Training Accuracy = 0.9900\n",
      "Iter 420, Minibatch Loss = 0.035958, Training Accuracy = 0.9900\n",
      "Iter 430, Minibatch Loss = 0.100213, Training Accuracy = 0.9500\n",
      "Iter 440, Minibatch Loss = 0.161598, Training Accuracy = 0.9500\n",
      "Iter 450, Minibatch Loss = 0.104842, Training Accuracy = 0.9600\n",
      "Iter 460, Minibatch Loss = 0.032137, Training Accuracy = 1.0000\n",
      "Iter 470, Minibatch Loss = 0.134061, Training Accuracy = 0.9400\n",
      "Iter 480, Minibatch Loss = 0.207038, Training Accuracy = 0.9500\n",
      "Iter 490, Minibatch Loss = 0.046918, Training Accuracy = 0.9900\n",
      "Model saved at Iter 500 !\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "while step < training_iters:\n",
    "    # Load a batch of data\n",
    "    images_batch, labels_batch = loader.next_batch(batch_size)\n",
    "        \n",
    "    # Run optimization (i.e. back propagation)\n",
    "    summary, _ = sess.run([merged, train_optimizer],\n",
    "                          feed_dict={x: images_batch, y: labels_batch, keep_dropout: dropout})\n",
    "    \n",
    "    # Display loss and accuracy every ``step_display`` iterations\n",
    "    if step % step_display == 0:\n",
    "        # Calculate batch loss and accuracy while training\n",
    "        l, acc = sess.run([loss, accuracy],\n",
    "                          feed_dict={x: images_batch, y: labels_batch, keep_dropout: 1.}) \n",
    "        print(\"Iter %d, Minibatch Loss = %.6f, Training Accuracy = %.4f\" % (step, l, acc))\n",
    "        \n",
    "    step += 1\n",
    "        \n",
    "    # Save model\n",
    "    if step % step_save == 0:\n",
    "        saver.save(sess, path_save, global_step=step)\n",
    "        print \"Model saved at Iter %d !\" %(step)\n",
    "\n",
    "    # Add summary to writer at each iteration\n",
    "    summary_writer.add_summary(summary, step)\n",
    "        \n",
    "print(\"Finished training!\")\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "After training, we can run the model on a test set to understand its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.979900\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for test images\n",
    "images_test, labels_test = loader.load_test()\n",
    "test_accuracy = sess.run(accuracy, feed_dict={x: images_test,\n",
    "                                              y: labels_test,\n",
    "                                              keep_dropout: 1.})\n",
    "print(\"Testing Accuracy: %f\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check Visualization in TensorBoard\n",
    "\n",
    "Since we write out summary to logs directory, we can use TensorFlow to see the stats we add to the summary.\n",
    "\n",
    "To launch TensorBoard, you should type this in your terminal or command prompt:\n",
    "\n",
    "    tensorboard --logdir=logs/\n",
    "    \n",
    "It will reads the files in logs/ directory.\n",
    "\n",
    "Then, in your favorite browser, go to ``localhost:6006`` to and click on \"Images\" tab to see visualization of filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done. Congrats!\n",
    "\n",
    "You have finished this tutorial. But, this is just a start, feel free to try different things on this simple CNN. For example,\n",
    "- add more layers\n",
    "- try different hyperparameters\n",
    "- add more stats to summary\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
